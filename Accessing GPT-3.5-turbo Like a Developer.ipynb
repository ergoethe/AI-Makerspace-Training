{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "LangChain and LlamaIndex are two different blockchain projects with their own unique features and functionalities.\n",
       "\n",
       "1. LangChain is a blockchain platform specifically designed for language learning and education. It uses blockchain technology to create a decentralized ecosystem where users can access language learning materials, connect with tutors, and participate in language exchange programs. LangChain also incorporates features such as smart contracts, token rewards, and decentralized applications to enhance the language learning experience.\n",
       "\n",
       "2. LlamaIndex, on the other hand, is a decentralized finance platform that focuses on providing users with access to a wide range of financial products and services. It offers features like decentralized exchanges, lending and borrowing platforms, and yield farming opportunities. LlamaIndex is designed to democratize access to traditional financial services and provide users with greater control over their assets.\n",
       "\n",
       "In summary, LangChain is focused on language learning and education, while LlamaIndex is focused on decentralized finance and financial services. Both projects leverage blockchain technology to create innovative solutions in their respective domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "That's amazing to hear! Keep spreading that joy and positivity! If there's anything specific you'd like to share or talk about, feel free to let me know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Her recipe for falbean soup was surprisingly stimple, requiring just a few basic ingredients and minimal cooking time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I need to use the stimple drill to attach the falbean to the wall."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Yes, it does matter which travel option Billy selects in order to arrive home before 7PM EDT.\n",
       "\n",
       "If Billy chooses to fly first, it will take him 3 hours to get from San Francisco to his destination. Since it is currently 1PM local time, Billy will arrive at his destination at 4PM local time. Then, it will take him an additional 2 hours to take the bus, so he will arrive at home at 6PM local time. Since Eastern Daylight Time (EDT) is 3 hours ahead of Pacific Daylight Time (PDT), Billy will arrive home at 9PM EDT, which is after 7PM EDT.\n",
       "\n",
       "On the other hand, if Billy chooses to take the teleporter first, he will arrive at his destination instantaneously. Then, it will take him 1 hour to take the bus, so he will arrive home at 2PM local time. Since EDT is 3 hours ahead of PDT, Billy will arrive home at 5PM EDT, which is before 7PM EDT.\n",
       "\n",
       "Therefore, Billy should choose the teleporter option in order to arrive home before 7PM EDT."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install openai cohere tiktoken -q\n",
    "\n",
    "import os\n",
    "import openai\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Please enter your OpenAI API Key: \")\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "YOUR_PROMPT = \"What is the difference between LangChain and LlamaIndex?\"\n",
    "\n",
    "## Helper functions\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def system_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"system\", \"content\": message}\n",
    "\n",
    "def assistant_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"assistant\", \"content\": message}\n",
    "\n",
    "def user_prompt(message: str) -> dict:\n",
    "    return {\"role\": \"user\", \"content\": message}\n",
    "\n",
    "def pretty_print(message: str) -> str:\n",
    "    display(Markdown(message.choices[0].message.content))\n",
    "\n",
    "## Get response from OpenAI\n",
    "\n",
    "def get_response(client: OpenAI, messages: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    return client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "messages = [user_prompt(YOUR_PROMPT)]\n",
    "chatgpt_response = get_response(client, messages)\n",
    "pretty_print(chatgpt_response)\n",
    "\n",
    "## System role message\n",
    "list_of_prompts[0]= system_prompt(\"You are joyful and having an awesome day!\")\n",
    "\n",
    "joyful_response = get_response(client, list_of_prompts)\n",
    "pretty_print(joyful_response)\n",
    "\n",
    "## Assistant role message\n",
    "list_of_prompts = [\n",
    "    user_prompt(\"Please use the words 'stimple' and 'falbean' in a sentence.\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(client, list_of_prompts)\n",
    "pretty_print(stimple_response)\n",
    "\n",
    "## Assistant role message #2\n",
    "list_of_prompts = [\n",
    "    user_prompt(\"Something that is 'stimple' is said to be good, well functioning, and high quality. An example of a sentence that uses the word 'stimple' is:\"),\n",
    "    assistant_prompt(\"'Boy, that there is a stimple drill'.\"),\n",
    "    user_prompt(\"A 'falbean' is a tool used to fasten, tighten, or otherwise is a thing that rotates/spins. An example of a sentence that uses the words 'stimple' and 'falbean' is:\")\n",
    "]\n",
    "\n",
    "stimple_response = get_response(client, list_of_prompts)\n",
    "pretty_print(stimple_response)\n",
    "\n",
    "\n",
    "## Chain of Thought Prompt and Reasoning\n",
    "reasoning_problem = \"\"\"\n",
    "Billy wants to get home from San Fran. before 7PM EDT.\n",
    "\n",
    "It's currently 1PM local time.\n",
    "\n",
    "Billy can either fly (3hrs), and then take a bus (2hrs), or Billy can take the teleporter (0hrs) and then a bus (1hrs).\n",
    "\n",
    "Does it matter which travel option Billy selects?\n",
    "\"\"\"\n",
    "\n",
    "list_of_prompts = [\n",
    "    user_prompt(reasoning_problem + \" Think through your response step by step.\")\n",
    "]\n",
    "\n",
    "reasoning_response = get_response(client, list_of_prompts)\n",
    "pretty_print(reasoning_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmops-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
